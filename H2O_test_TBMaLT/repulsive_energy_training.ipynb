{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f925de9d",
   "metadata": {},
   "source": [
    "# Repulsive Energy Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387a708",
   "metadata": {},
   "source": [
    "## 1.1 Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513b31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tbmalt.physics.dftb.feeds import RepulsiveSplineFeed\n",
    "from tbmalt.ml.loss_function import Loss, mse_loss\n",
    "\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "# This must be set until typecasting from HDF5 databases has been implemented.\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc005e02",
   "metadata": {},
   "source": [
    "## 1.2 Setting up the molecular systems for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eff86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reference of target properties\n",
    "targets = {'repulsive_energy': torch.tensor([0.0727])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd751d4",
   "metadata": {},
   "source": [
    "## 1.3 Setting up the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3845c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of training cycles\n",
    "number_of_epochs = 5000\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.1\n",
    "\n",
    "# Loss function\n",
    "loss_func = mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5627f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import warnings\n",
    "# from itertools import combinations_with_replacement # No longer needed for from_database\n",
    "from typing import List, Literal, Optional, Dict, Tuple, Union, Type\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from tbmalt import Geometry\n",
    "# from tbmalt.io.skf import Skf # No longer needed for Skf.RSpline\n",
    "from tbmalt.ml import Feed\n",
    "\n",
    "class RepulsiveSplineFeed(Feed):\n",
    "    r\"\"\"Repulsive Feed for DFTB-like calculations using a custom pairwise potential.\n",
    "\n",
    "    This class calculates repulsive energy based on effective nuclear charges (Z_eff)\n",
    "    and parameters (alpha) for pairs of atoms.\n",
    "    The original spline-based calculation is replaced by the new formula.\n",
    "\n",
    "    Arguments:\n",
    "        Z_eff_map: Dictionary mapping atomic numbers (int) to their effective\n",
    "                   nuclear charge (float or Tensor).\n",
    "        alpha_map: Dictionary mapping atomic numbers (int) to their alpha\n",
    "                   parameter (float or Tensor).\n",
    "        device: Device on which the feed object and its contents reside.\n",
    "        dtype: Floating point dtype to be used for tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 Z_eff_map: Dict[int, Union[float, Tensor]], \n",
    "                 alpha_map: Dict[int, Union[float, Tensor]],\n",
    "                 device: Optional[torch.device] = None,\n",
    "                 dtype: Optional[torch.dtype] = torch.float64):\n",
    "        super().__init__()\n",
    "\n",
    "        self._device = device if device is not None else torch.device('cpu')\n",
    "        self._dtype = dtype if dtype is not None else torch.float64\n",
    "\n",
    "        self.Z_eff_map = {\n",
    "            k: (v if isinstance(v, Tensor) else torch.tensor(v, device=self._device, dtype=self._dtype))\n",
    "            for k, v in Z_eff_map.items()\n",
    "        }\n",
    "        self.alpha_map = {\n",
    "            k: (v if isinstance(v, Tensor) else torch.tensor(v, device=self._device, dtype=self._dtype))\n",
    "            for k, v in alpha_map.items()\n",
    "        }\n",
    "\n",
    "        # Ensure all tensors in maps are on the correct device and dtype\n",
    "        for Z_map_k in self.Z_eff_map:\n",
    "            if self.Z_eff_map[Z_map_k].device != self._device or self.Z_eff_map[Z_map_k].dtype != self._dtype:\n",
    "                self.Z_eff_map[Z_map_k] = self.Z_eff_map[Z_map_k].to(device=self._device, dtype=self._dtype)\n",
    "        for alpha_map_k in self.alpha_map:\n",
    "            if self.alpha_map[alpha_map_k].device != self._device or self.alpha_map[alpha_map_k].dtype != self._dtype:\n",
    "                 self.alpha_map[alpha_map_k] = self.alpha_map[alpha_map_k].to(device=self._device, dtype=self._dtype)\n",
    "\n",
    "\n",
    "        warnings.warn(\n",
    "            \"The `RepulsiveSplineFeed` class is now deprecated and will be \"\n",
    "            \"removed. Its repulsive calculation logic has been changed from splines \"\n",
    "            \"to a custom pairwise potential. Consider using a more appropriately named \"\n",
    "            \"class or `PairwiseRepulsiveEnergyFeed` with a custom potential function.\",\n",
    "            category=DeprecationWarning)\n",
    "\n",
    "    @property\n",
    "    def dtype(self) -> torch.dtype:\n",
    "        \"\"\"Floating point dtype used by `RepulsiveSplineFeed` object.\"\"\"\n",
    "        return self._dtype\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        \"\"\"The device on which the `RepulsiveSplineFeed` object resides.\"\"\"\n",
    "        return self._device\n",
    "\n",
    "    def __call__(self, geo: Geometry) -> Tensor:\n",
    "        r\"\"\"Calculate the repulsive energy of a Geometry.\n",
    "\n",
    "        Arguments:\n",
    "            geo: `Geometry` object representing the system, or batch thereof,\n",
    "                for which the repulsive energy should be calculated.\n",
    "\n",
    "        Returns:\n",
    "            Erep: The repulsive energy of the Geometry object(s).\n",
    "        \"\"\"\n",
    "        batch_size, _, indx_pairs, _ = self._calculation_prep(geo)\n",
    "        \n",
    "        Erep = torch.zeros((batch_size), device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        for indx_pair in indx_pairs:\n",
    "            # Ensure indices are integers for geo.atomic_numbers access\n",
    "            idx0, idx1 = int(indx_pair[0]), int(indx_pair[1])\n",
    "\n",
    "            atomnum1_all = geo.atomic_numbers[..., idx0].reshape((batch_size, ))\n",
    "            atomnum2_all = geo.atomic_numbers[..., idx1].reshape((batch_size, ))\n",
    "            distance_all = geo.distances[..., idx0, idx1].reshape((batch_size, ))\n",
    "\n",
    "            for batch_indx in range(batch_size):\n",
    "                atomnum1 = int(atomnum1_all[batch_indx].item())\n",
    "                atomnum2 = int(atomnum2_all[batch_indx].item())\n",
    "                distance = distance_all[batch_indx]\n",
    "\n",
    "                if atomnum1 == 0 or atomnum2 == 0: # Skip dummy atoms\n",
    "                    continue\n",
    "                \n",
    "                # Retrieve parameters for the specific atom pair\n",
    "                try:\n",
    "                    Z_A_eff = self.Z_eff_map[atomnum1]\n",
    "                    Z_B_eff = self.Z_eff_map[atomnum2]\n",
    "                    alpha_A = self.alpha_map[atomnum1]\n",
    "                    alpha_B = self.alpha_map[atomnum2]\n",
    "                except KeyError as e:\n",
    "                    raise KeyError(f\"Missing Z_eff or alpha parameter for atomic number {e} in maps.\") from e\n",
    "\n",
    "                add_Erep = self._repulsive_calc(distance, Z_A_eff, Z_B_eff, alpha_A, alpha_B, grad=False)\n",
    "                Erep[batch_indx] += add_Erep\n",
    "        return Erep\n",
    "\n",
    "    def gradient(self, geo: Geometry) -> Tensor:\n",
    "        \"\"\"Calculate the gradient of the repulsive energy.\n",
    "\n",
    "        Arguments:\n",
    "            geo: `Geometry` object representing the system, or batch thereof,\n",
    "                for which the gradient of the repulsive energy should be\n",
    "                calculated.\n",
    "\n",
    "        returns:\n",
    "            dErep: The gradient of the repulsive energy.\n",
    "        \"\"\"\n",
    "        batch_size, _, indx_pairs, normed_distance_vectors = self._calculation_prep(geo)\n",
    "        \n",
    "        dErep = torch.zeros((batch_size, geo.atomic_numbers.size(dim=-1), 3), device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        for indx_pair in indx_pairs:\n",
    "            # Ensure indices are integers\n",
    "            idx0, idx1 = int(indx_pair[0]), int(indx_pair[1])\n",
    "\n",
    "            atomnum1_all = geo.atomic_numbers[..., idx0].reshape((batch_size, ))\n",
    "            atomnum2_all = geo.atomic_numbers[..., idx1].reshape((batch_size, ))\n",
    "            distance_all = geo.distances[..., idx0, idx1].reshape((batch_size, ))\n",
    "\n",
    "            for batch_indx in range(batch_size):\n",
    "                atomnum1 = int(atomnum1_all[batch_indx].item())\n",
    "                atomnum2 = int(atomnum2_all[batch_indx].item())\n",
    "                distance = distance_all[batch_indx]\n",
    "\n",
    "                if atomnum1 == 0 or atomnum2 == 0: # Skip dummy atoms\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    Z_A_eff = self.Z_eff_map[atomnum1]\n",
    "                    Z_B_eff = self.Z_eff_map[atomnum2]\n",
    "                    alpha_A = self.alpha_map[atomnum1]\n",
    "                    alpha_B = self.alpha_map[atomnum2]\n",
    "                except KeyError as e:\n",
    "                    raise KeyError(f\"Missing Z_eff or alpha parameter for atomic number {e} in maps.\") from e\n",
    "                \n",
    "                # Calculate dE/dR (scalar derivative)\n",
    "                scalar_grad_Erep = self._repulsive_calc(\n",
    "                    distance, Z_A_eff, Z_B_eff, alpha_A, alpha_B, grad=True)\n",
    "                \n",
    "                # Get normalized distance vector for this pair in this batch item\n",
    "                # Ensure normed_distance_vectors access is correct for batch_indx\n",
    "                norm_vec_ij = normed_distance_vectors[batch_indx, idx0, idx1]\n",
    "                norm_vec_ji = normed_distance_vectors[batch_indx, idx1, idx0] # Should be -norm_vec_ij\n",
    "\n",
    "                # Distribute gradient to atoms: dE/dr_i = (dE/dR) * (dr/dr_i) = (dE/dR) * u_ij\n",
    "                # Force on atom i is -dE/dr_i\n",
    "                # Gradient component for atom i is (dE/dR) * u_ij\n",
    "                # Gradient component for atom j is (dE/dR) * u_ji = (dE/dR) * (-u_ij)\n",
    "                dErep[batch_indx, idx0] += scalar_grad_Erep * norm_vec_ij\n",
    "                dErep[batch_indx, idx1] += scalar_grad_Erep * norm_vec_ji\n",
    "        \n",
    "        if batch_size == 1 and dErep.shape[0] == 1: # Ensure squeeze is safe\n",
    "            dErep = dErep.squeeze(0)\n",
    "        return dErep\n",
    "\n",
    "    def _calculation_prep(self, geo: Geometry\n",
    "                          ) -> Tuple[int, Tensor, Tensor, Tensor]:\n",
    "        \"\"\"Preliminaries for repulsive energy & gradient calculation.\n",
    "\n",
    "        Arguments:\n",
    "            geo: `Geometry` object representing the system, or batch thereof,\n",
    "                for which the calculation preparation steps are to be performed.\n",
    "\n",
    "        returns:\n",
    "            batch_size: The number of geometries in the batch.\n",
    "            indxs: The indices of the atoms.\n",
    "            indx_pairs: The indices of the interacting atom pairs as tuples.\n",
    "            normed_distance_vectors: The normalized distance vectors between the atoms\n",
    "        \"\"\"\n",
    "        if geo.atomic_numbers.dim() == 1: # this means it is not a batch\n",
    "            atomic_numbers_batched = geo.atomic_numbers.unsqueeze(0)\n",
    "            if geo.distances.dim() == 2: # (n_atoms, n_atoms)\n",
    "                 distances_batched = geo.distances.unsqueeze(0)\n",
    "                 distance_vectors_batched = geo.distance_vectors.unsqueeze(0)\n",
    "            else: # already (1, n_atoms, n_atoms)\n",
    "                 distances_batched = geo.distances\n",
    "                 distance_vectors_batched = geo.distance_vectors\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            atomic_numbers_batched = geo.atomic_numbers\n",
    "            distances_batched = geo.distances\n",
    "            distance_vectors_batched = geo.distance_vectors\n",
    "            batch_size = atomic_numbers_batched.size(dim=0)\n",
    "\n",
    "        n_atoms = atomic_numbers_batched.size(dim=-1)\n",
    "        indxs = torch.arange(n_atoms, device=self.device) # Use self.device\n",
    "        # combinations creates pairs like (0,1), (0,2), (1,2) etc.\n",
    "        # It's important that these indices match how geo.distances are indexed.\n",
    "        # geo.distances[..., i, j] is distance between atom i and atom j.\n",
    "        indx_pairs = torch.combinations(indxs, r=2)\n",
    "\n",
    "\n",
    "        # Handle division by zero for distances if atoms are at the same position\n",
    "        # Add a small epsilon to distances in denominator to prevent NaN in normed_distance_vectors\n",
    "        epsilon_dist = torch.tensor(1e-12, device=distances_batched.device, dtype=distances_batched.dtype)\n",
    "        # This is R_AB, shape (batch_size, n_atoms, n_atoms)\n",
    "        safe_distances = torch.max(distances_batched, epsilon_dist)\n",
    "\n",
    "        # normed_distance_vectors shape (batch_size, n_atoms, n_atoms, 3)\n",
    "        normed_distance_vectors = distance_vectors_batched / safe_distances.unsqueeze(-1)\n",
    "        \n",
    "        # Where original distance was truly zero, the vector was [0,0,0], so 0/epsilon resulted in 0.\n",
    "        # If distance_vectors was [0,0,0] and distances was 0, then 0/epsilon is 0.\n",
    "        # If distance_vectors was non-zero (should not happen if distance is 0) and distance was 0, then non-zero/epsilon.\n",
    "        # A more robust way if distances_batched can be zero:\n",
    "        # zero_dist_mask = (distances_batched == 0.0)\n",
    "        # normed_distance_vectors[zero_dist_mask.unsqueeze(-1).expand_as(distance_vectors_batched)] = 0.0\n",
    "        # However, the above max(distances_batched, epsilon_dist) handles the division part.\n",
    "        # If geo.distances[i,j] is 0, geo.distance_vectors[i,j,:] should also be [0,0,0].\n",
    "        # So [0,0,0] / epsilon is [0,0,0]. This seems fine.\n",
    "\n",
    "        # The original code had:\n",
    "        # normed_distance_vectors = geo.distance_vectors / geo.distances.unsqueeze(-1)\n",
    "        # normed_distance_vectors[normed_distance_vectors.isnan()] = 0\n",
    "        # This is also a valid way to handle it. Using max with epsilon avoids NaNs from division by zero directly.\n",
    "\n",
    "        # Reshape not strictly necessary if subsequent code uses (batch, N, N, 3) directly\n",
    "        # but keeping if other parts rely on this specific view for normed_distance_vectors\n",
    "        # The original reshape was:\n",
    "        # normed_distance_vectors = torch.reshape(\n",
    "        # normed_distance_vectors, (\n",
    "        # batch_size, normed_distance_vectors.shape[-3], # n_atoms\n",
    "        # normed_distance_vectors.shape[-2], # n_atoms\n",
    "        # normed_distance_vectors.shape[-1])) # 3\n",
    "        # This reshape is redundant if normed_distance_vectors is already (batch_size, n_atoms, n_atoms, 3)\n",
    "\n",
    "        return batch_size, indxs, indx_pairs, normed_distance_vectors\n",
    "\n",
    "    def _repulsive_calc(\n",
    "            self, \n",
    "            distance: Tensor, \n",
    "            Z_A_eff: Tensor, \n",
    "            Z_B_eff: Tensor,\n",
    "            alpha_A: Tensor, \n",
    "            alpha_B: Tensor, \n",
    "            grad: bool = False\n",
    "        ) -> Tensor:\n",
    "        \"\"\"Calculate the repulsive energy or its derivative between two atoms.\n",
    "        \n",
    "        Formula: E_rep = (Z_A_eff * Z_B_eff / R_AB) + exp(-sqrt(alpha_A * alpha_B) * R_AB^k_f)\n",
    "        where k_f = 1.5.\n",
    "\n",
    "        Arguments:\n",
    "            distance (R_AB): The distance between the two atoms.\n",
    "            Z_A_eff: Effective nuclear charge of atom A.\n",
    "            Z_B_eff: Effective nuclear charge of atom B.\n",
    "            alpha_A: Alpha parameter for atom A.\n",
    "            alpha_B: Alpha parameter for atom B.\n",
    "            grad: If True, calculate and return the derivative dE_rep/dR_AB.\n",
    "                  Otherwise, return E_rep.\n",
    "\n",
    "        Returns:\n",
    "            Repulsive energy or its derivative with respect to distance.\n",
    "        \"\"\"\n",
    "        k_f = 1.5\n",
    "        R_AB = distance # Use R_AB as the variable for clarity with the formula\n",
    "\n",
    "        # Ensure alpha parameters are non-negative for sqrt\n",
    "        # Assuming alpha values from map are already appropriate (e.g. >= 0)\n",
    "        # Add a small epsilon to R_AB in division to prevent inf/NaN if R_AB can be zero.\n",
    "        # However, standard torch division 1.0/0.0 = inf. Gradient of 1/R is -1/R^2.\n",
    "        # If R_AB is truly 0.0, energy is infinite. Gradient is also infinite.\n",
    "        # This is often the desired physical behavior at singularity.\n",
    "        # Clamping can be used if finite values are strictly needed for R_AB -> 0.\n",
    "        # For now, let torch handle potential infinities.\n",
    "        \n",
    "        # Term 1: Coulombic-like repulsion\n",
    "        term1 = (Z_A_eff * Z_B_eff) / R_AB\n",
    "\n",
    "        # Term 2: Exponential repulsion\n",
    "        sqrt_alpha_prod = torch.sqrt(alpha_A * alpha_B) # Assuming alpha_A, alpha_B >= 0\n",
    "        # R_AB ** k_f can be problematic if R_AB is negative, but distances are non-negative.\n",
    "        # If R_AB = 0, R_AB ** k_f = 0 (for k_f > 0).\n",
    "        exp_argument = -sqrt_alpha_prod * (R_AB ** k_f)\n",
    "        term2 = torch.exp(exp_argument)\n",
    "\n",
    "        if not grad:\n",
    "            repulsive_energy = term1 * term2\n",
    "            return repulsive_energy\n",
    "        else:\n",
    "            # Derivative of term1: d(C/R)/dR = -C/R^2\n",
    "            grad_term1 = - (Z_A_eff * Z_B_eff) / (R_AB ** 2)\n",
    "\n",
    "            # Derivative of term2: d(exp(-A * R^k_f))/dR\n",
    "            # = exp(-A * R^k_f) * (-A * k_f * R^(k_f-1))\n",
    "            # where A = sqrt(alpha_A * alpha_B)\n",
    "            # R_AB**(k_f - 1.0): if R_AB=0 and k_f-1=0.5, this is 0.0.\n",
    "            # If R_AB is very small, this derivative term dominates.\n",
    "            # If R_AB is 0, and k_f-1 > 0, then R_AB**(k_f-1) is 0, so grad_term2 is 0.\n",
    "            # This means at R_AB=0, only the Coulombic gradient remains ( انفجاری).\n",
    "            \n",
    "            # Check for R_AB == 0 to handle R_AB**(k_f-1) correctly\n",
    "            # if R_AB is a tensor, direct comparison might be needed with tolerance or use torch.where\n",
    "            if R_AB == 0.0: # Exact zero\n",
    "                 # grad_term1 will be -inf or inf (or nan if Z_A_eff*Z_B_eff is also 0)\n",
    "                 # grad_term2 contribution is 0 because R_AB**(k_f-1.0) = 0.0**(0.5) = 0.0\n",
    "                 grad_term2 = torch.tensor(0.0, device=R_AB.device, dtype=R_AB.dtype)\n",
    "            else:\n",
    "                 grad_term2 = term2 * (-sqrt_alpha_prod * k_f * (R_AB ** (k_f - 1.0)))\n",
    "            \n",
    "            return grad_term1 * grad_term2\n",
    "\n",
    "    @classmethod\n",
    "    def from_database(\n",
    "            cls, path: str, species: List[int],\n",
    "            dtype: Optional[torch.dtype] = None,\n",
    "            device: Optional[torch.device] = None\n",
    "            ) -> 'RepulsiveSplineFeed':\n",
    "        r\"\"\"Instantiate instance from a HDF5 database of Slater-Koster files.\n",
    "        \n",
    "        NOTE: This method is currently NOT IMPLEMENTED for the new repulsive\n",
    "        potential form. The original `from_database` was designed to load\n",
    "        spline data from SKF files. To use this class, you need to provide\n",
    "        `Z_eff_map` and `alpha_map` directly to the constructor.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"from_database is not implemented for the current repulsive potential form. \"\n",
    "            \"Please provide Z_eff_map and alpha_map directly to the constructor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a7607",
   "metadata": {},
   "source": [
    "## 1.4 Input the molecular systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39de93a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometry: Geometry(OH2)\n",
      "OrbitalInfo: <tbmalt.structures.orbitalinfo.OrbitalInfo object at 0x75117290e210>\n"
     ]
    }
   ],
   "source": [
    "from tbmalt import Geometry, OrbitalInfo\n",
    "shell_dict = {1: [0], 6: [0, 1], 7: [0, 1], 8: [0, 1]}\n",
    "\n",
    "device = torch.device('cpu')\n",
    "# Construct the `Geometry` and `OrbitalInfo` objects. The former is analogous\n",
    "# to the ase.Atoms object while the latter provides information about what\n",
    "# orbitals are present and which atoms they belong to.\n",
    "geometry = Geometry(\n",
    "        torch.tensor([8,1,1], device=device),\n",
    "        torch.tensor([\n",
    "            [0.00000000, -0.71603315, -0.00000000],\n",
    "            [0.00000000, -0.14200298, 0.77844804 ],\n",
    "            [-0.00000000, -0.14200298, -0.77844804]],\n",
    "            device=device),units='a')\n",
    "\n",
    "orbs = OrbitalInfo(geometry.atomic_numbers, shell_dict)\n",
    "\n",
    "print('Geometry:', geometry)\n",
    "print('OrbitalInfo:', orbs)\n",
    "\n",
    "# Identify which species are present\n",
    "species = torch.unique(geometry.atomic_numbers)\n",
    "# Strip out padding species and convert to a standard list.\n",
    "species = species[species != 0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c7f993",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140421b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z_H_eff = 1.116244\n",
    "z_effs = {\n",
    "    1: torch.nn.Parameter(torch.rand(())),  # Hydrogen\n",
    "    8: torch.tensor(5.171786)   # Oxygen\n",
    "}\n",
    "alphas = {\n",
    "    1: torch.tensor(2.209700),  # Hydrogen\n",
    "    8: torch.tensor(2.004253)   # Oxygen\n",
    "}\n",
    "\n",
    "parameter = z_effs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e45761",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([parameter], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546dd530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1638/672218363.py:55: DeprecationWarning: The `RepulsiveSplineFeed` class is now deprecated and will be removed. Its repulsive calculation logic has been changed from splines to a custom pairwise potential. Consider using a more appropriately named class or `PairwiseRepulsiveEnergyFeed` with a custom potential function.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9912e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9756e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9601e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9446e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9290e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9136e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8981e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8827e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8673e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8519e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8365e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8212e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8059e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7906e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7753e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7601e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7449e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7297e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7145e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6994e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6842e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6691e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6541e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6390e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6240e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6090e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5940e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5790e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5641e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5492e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5343e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5194e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5046e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4898e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4750e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4602e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4455e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4307e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4160e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4013e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3867e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3721e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3574e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3428e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3283e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3137e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2992e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2847e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2702e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2558e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2414e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2270e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2126e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1982e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1839e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1695e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1552e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1410e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1267e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1125e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0983e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0841e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0699e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0558e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0417e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0276e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0135e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9994e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9854e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9714e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9574e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9435e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9295e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9156e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9017e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8878e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8740e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8601e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8463e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8325e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8187e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8050e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7913e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7776e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7639e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7502e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7366e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7229e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7093e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6958e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6822e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6687e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6552e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6417e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6282e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6147e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6013e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5879e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5745e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5611e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5478e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5345e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5211e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5079e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4946e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4814e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4681e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4549e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4417e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4286e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4154e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4023e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3892e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3761e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3631e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3500e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3370e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3240e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3110e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2981e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2852e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2722e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2593e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2465e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2336e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2208e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2079e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1952e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1824e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1696e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1569e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1442e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1315e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1188e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1061e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0935e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0809e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0683e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0557e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0431e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0306e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0181e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0056e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9931e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9806e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9682e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9558e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9434e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9310e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9186e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9063e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8939e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8816e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8693e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8571e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8448e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8326e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8204e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8082e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7960e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7839e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7717e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7596e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7475e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7354e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7234e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7113e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6993e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6873e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6753e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6633e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6514e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6395e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6275e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6157e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6038e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5919e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5801e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5683e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5565e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5447e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5329e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5212e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5095e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4977e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4861e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4744e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4627e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4511e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4395e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4279e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4163e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4047e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3932e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3817e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3702e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3587e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3472e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3357e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3243e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3129e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3015e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2901e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2787e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2674e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2560e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2447e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2334e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2222e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2109e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1997e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1884e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1772e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1660e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1549e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1437e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1326e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1214e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1103e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0993e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0882e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0771e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0661e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0551e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0441e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0331e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0221e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0112e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0003e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9893e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9784e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9676e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9567e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9459e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9350e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9242e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9134e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9026e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8919e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8811e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8704e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8597e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8490e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8383e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8277e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8170e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8064e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7958e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7852e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7746e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7640e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7535e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7430e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7324e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7219e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7115e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7010e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6906e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6801e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6697e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6593e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6489e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6386e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6282e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6179e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6076e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5973e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5870e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5767e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5664e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5562e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5460e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5358e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5256e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5154e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5053e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4951e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4850e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4749e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4648e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4547e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4446e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4346e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4246e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4145e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4045e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3946e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3846e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3746e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3647e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3548e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3449e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3350e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3251e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3152e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3054e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2955e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2857e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2759e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2661e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2564e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2466e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2369e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2272e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2174e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2078e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1981e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1884e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1788e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1691e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1595e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1499e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1403e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1307e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1212e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1116e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1021e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0926e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0831e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0736e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0641e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0547e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0453e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0358e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0264e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0170e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0076e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9983e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9889e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9796e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9703e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9610e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9517e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9424e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9331e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9239e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9146e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9054e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8962e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8870e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8778e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8687e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8595e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8504e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8413e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8321e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8231e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8140e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8049e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7959e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7868e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7778e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7688e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7598e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7508e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7418e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7329e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7240e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7150e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7061e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6972e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6883e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6795e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6706e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6618e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6529e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6441e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6353e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6265e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6178e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6090e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6003e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5915e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5828e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5741e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5654e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5567e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5481e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5394e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5308e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5222e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5136e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5050e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4964e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4878e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4793e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4707e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4622e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4537e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4452e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4367e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4282e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4197e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4113e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4029e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3944e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3860e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3776e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3692e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3609e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3525e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3442e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3358e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3275e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3192e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3109e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3026e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2944e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2861e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2779e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2696e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2614e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2532e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2450e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2368e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2287e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2205e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2124e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2043e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1961e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1880e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1800e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1719e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1638e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1558e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1477e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1397e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1317e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1237e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1157e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1077e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0998e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0918e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0839e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0759e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0680e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0601e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0522e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0444e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0365e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0286e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0208e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0130e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0052e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9974e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9896e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9818e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9740e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9663e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9585e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9508e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9431e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9354e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9277e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9200e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9123e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9046e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8970e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8894e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8817e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8741e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8665e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8589e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8514e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8438e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8363e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8287e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8212e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8137e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8062e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7987e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7912e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7837e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7763e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7688e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7614e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7539e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7465e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7391e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7317e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7244e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7170e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7096e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7023e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6950e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6877e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6803e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6730e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6658e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6585e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6512e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6440e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6367e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6295e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6223e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6151e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6079e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6007e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5935e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5864e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5792e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5721e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5649e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5578e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5507e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5436e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5365e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5295e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5224e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5154e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5083e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5013e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4943e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4873e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4803e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4733e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4663e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4593e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4524e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4454e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4385e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4316e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4247e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4178e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4109e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4040e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3972e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3903e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3834e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3766e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3698e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3630e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3562e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3494e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3426e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3358e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3291e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3223e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3156e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3089e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3021e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2954e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2887e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2820e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2754e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2687e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2620e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2554e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2488e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2421e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2355e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2289e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2223e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2157e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2092e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2026e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1961e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1895e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1830e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1765e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1699e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1634e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1570e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1505e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1440e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1375e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1311e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1246e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1182e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1118e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1054e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0990e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0926e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0862e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0798e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0735e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0671e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0608e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0545e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0481e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0418e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0355e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0292e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0229e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0167e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0104e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0042e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9979e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9917e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9855e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9792e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9730e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9668e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9607e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9545e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9483e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9422e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9360e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9299e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9238e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9176e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9115e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9054e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8993e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8933e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8872e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8811e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8751e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8690e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8630e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8570e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8510e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8450e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8390e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8330e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8270e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8210e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8151e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8091e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8032e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7973e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7913e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7854e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7795e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7736e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7678e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7619e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7560e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7502e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7443e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7385e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7326e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7268e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7210e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7152e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7094e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7036e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6979e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6921e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6863e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6806e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6748e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6691e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6634e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6577e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6520e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6463e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6406e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6349e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6293e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6236e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6180e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6123e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6067e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6011e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5954e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5898e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5842e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5786e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5731e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5675e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5619e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5564e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5508e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5453e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5398e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5343e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5287e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5232e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5177e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5123e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5068e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5013e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4959e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4904e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4850e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4795e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4741e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4687e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4633e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4579e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4525e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4471e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4417e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4364e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4310e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4257e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4203e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4150e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4097e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4043e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3990e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3937e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3884e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3832e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3779e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3726e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3674e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3621e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3569e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3516e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3464e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3412e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3360e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3308e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3256e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3204e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3152e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3101e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3049e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2997e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2946e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2895e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2843e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2792e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2741e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2690e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2639e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2588e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2537e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2487e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2436e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2385e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2335e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2284e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2234e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2184e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2134e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2084e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2034e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1984e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1934e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1884e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1834e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1785e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1735e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1686e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1636e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1587e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1538e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1488e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1439e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1390e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1341e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1292e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1244e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1195e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1146e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1098e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1049e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1001e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0952e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0904e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0856e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0808e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0760e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0712e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0664e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0616e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0569e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0521e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0473e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0426e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0378e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0331e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0284e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0236e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0189e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0142e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0095e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0048e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0001e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9955e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9908e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9861e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9815e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9768e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9722e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9676e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9629e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9583e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9537e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9491e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9445e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9399e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9353e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9307e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9262e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9216e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9171e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9125e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9080e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9034e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8989e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8944e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8899e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8854e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8809e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8764e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8719e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8674e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8629e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8585e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8540e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8496e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8451e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8407e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8363e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8318e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8274e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8230e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8186e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8142e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8098e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8054e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8011e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7967e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7923e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7880e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7836e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7793e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7750e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7706e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7663e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7620e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7577e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7534e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7491e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7448e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7405e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7363e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7320e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7277e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7235e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7192e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7150e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7108e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7065e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7023e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6981e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6939e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6897e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6855e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6813e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6771e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6730e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6688e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6646e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6605e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6563e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6522e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6481e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6439e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6398e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6357e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6316e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6275e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6234e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6193e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6152e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6111e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6071e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6030e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5989e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5949e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5908e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5868e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5828e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5787e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5747e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5707e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5667e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5627e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5587e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5547e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5507e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5467e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5428e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5388e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5349e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5309e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5270e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5230e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5191e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5152e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5112e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5073e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5034e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4995e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4956e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4917e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4878e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4840e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4801e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4762e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4724e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4685e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4646e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4608e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4570e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4531e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4493e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4455e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4417e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4379e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4341e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4303e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4265e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4227e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4189e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4152e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4114e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4076e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4039e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4001e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3964e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3926e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3889e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3852e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3815e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3778e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3741e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3704e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3667e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3630e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3593e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3556e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3519e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3483e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3446e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3409e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3373e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3337e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3300e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3264e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3228e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3191e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3155e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3119e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3083e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3047e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3011e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2975e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2939e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2904e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2868e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2832e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2797e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2761e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2726e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2690e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2655e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2619e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2584e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2549e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2514e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2479e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2444e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2409e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2374e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2339e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2304e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2269e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2235e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2200e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2165e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2131e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2096e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2062e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2027e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1993e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1959e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1924e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1890e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1856e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1822e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1788e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1754e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1720e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1686e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1652e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1619e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1585e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1551e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1518e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1484e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1451e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1417e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1384e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1351e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1317e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1284e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1251e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1218e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1185e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1152e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1119e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1086e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1053e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1020e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0987e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0954e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0922e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0889e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0857e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0824e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0792e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0759e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0727e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0695e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0662e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0630e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0598e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0566e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0534e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0502e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0470e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0438e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0406e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0374e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0342e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0311e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0279e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0247e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0216e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0184e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0153e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0121e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0090e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0059e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0027e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9996e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9965e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9934e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9903e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9872e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9841e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9810e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9779e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9748e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9717e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9687e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9656e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9625e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9595e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9564e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9534e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9503e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9473e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9442e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9412e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9382e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9352e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9321e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9291e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9261e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9231e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9201e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9171e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9141e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9111e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9082e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9052e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9022e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8993e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8963e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8933e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8904e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8874e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8845e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8816e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8786e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8757e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8728e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8698e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8669e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8640e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8611e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8582e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8553e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8524e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8495e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8466e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8438e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8409e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8380e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8352e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8323e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8294e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8266e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8237e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8209e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8181e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8152e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8124e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8096e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8067e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8039e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8011e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7983e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7955e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7927e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7899e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7871e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7843e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7815e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7788e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7760e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7732e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7705e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7677e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7649e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7622e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7594e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7567e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7540e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7512e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7485e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7458e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7431e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7403e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7376e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7349e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7322e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7295e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7268e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7241e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7214e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7187e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7161e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7134e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7107e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7080e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7054e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7027e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7001e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6974e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6948e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6921e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6895e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6869e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6842e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6816e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6790e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6764e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6737e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6711e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6685e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6659e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6633e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6607e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6582e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6556e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6530e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6504e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6478e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6453e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6427e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6401e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6376e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6350e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6325e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6299e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6274e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6249e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6223e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6198e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6173e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6147e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6122e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6097e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6072e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6047e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6022e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5997e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5972e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5947e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5922e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5897e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5873e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5848e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5823e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5799e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5774e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5749e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5725e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5700e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5676e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5651e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5627e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5603e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5578e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5554e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5530e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5505e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5481e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5457e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5433e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5409e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5385e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5361e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5337e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5313e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5289e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5265e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5242e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5218e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5194e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5170e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5147e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5123e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5100e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5076e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5052e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5029e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5006e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4982e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4959e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4935e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4912e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4889e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4866e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4843e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4819e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4796e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4773e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4750e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4727e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4704e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4681e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4658e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4636e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4613e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4590e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4567e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4544e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4522e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4499e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4477e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4454e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4431e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4409e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4386e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4364e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4342e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4319e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4297e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4275e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4252e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4230e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4208e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4186e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4164e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4142e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4120e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4098e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4076e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4054e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4032e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4010e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3988e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3966e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3944e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3923e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3901e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3879e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3858e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3836e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3814e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3793e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3771e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3750e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3729e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3707e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3686e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3664e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3643e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3622e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3601e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3579e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3558e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3537e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3516e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3495e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3474e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3453e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3432e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3411e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3390e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3369e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3348e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3327e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3307e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3286e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3265e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3245e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3224e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3203e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3183e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3162e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3142e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3121e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3101e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3080e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3060e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3039e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3019e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2999e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2979e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2958e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2938e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2918e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2898e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2878e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2858e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2838e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2818e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2798e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2778e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2758e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2738e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2718e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2698e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2678e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2659e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2639e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2619e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2599e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2580e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2560e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2541e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2521e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2502e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2482e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2463e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2443e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2424e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2404e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2385e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2366e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2346e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2327e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2308e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2289e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2270e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2250e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2231e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2212e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2193e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2174e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2155e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2136e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2117e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2099e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2080e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2061e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2042e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2023e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2004e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1986e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1967e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1948e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1930e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1911e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1893e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1874e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1856e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1837e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1819e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1800e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1782e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1763e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1745e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1727e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1708e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1690e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1672e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1654e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1636e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1617e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1599e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1581e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1563e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1545e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1527e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1509e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1491e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1473e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1455e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1438e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1420e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1402e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1384e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1366e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1349e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1331e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1313e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1296e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1278e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1261e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1243e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1225e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1208e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1190e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1173e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1156e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1138e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1121e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1103e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1086e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1069e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1052e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1034e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1017e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1000e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0983e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0966e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0949e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0932e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0915e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0897e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0881e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0864e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0847e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0830e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0813e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0796e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0779e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0762e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0746e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0729e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0712e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0695e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0679e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0662e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0645e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0629e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0612e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0596e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0579e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0563e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0546e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0530e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0513e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0497e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0481e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0464e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0448e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0432e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0415e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0399e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0383e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0367e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0351e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0334e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0318e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0302e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0286e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0270e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0254e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0238e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0222e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0206e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0190e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0174e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0159e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0143e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0127e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0111e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0095e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0080e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0064e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0048e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0032e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0017e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0001e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9856e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9701e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9545e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9390e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9235e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9080e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8926e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8772e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8618e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8464e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8310e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8157e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8004e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7851e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7699e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7546e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7394e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7242e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7091e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6939e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6788e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6637e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6487e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6336e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6186e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6036e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5886e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5737e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5587e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5438e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5290e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5141e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4993e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4845e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4697e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4549e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4402e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4254e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4107e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3961e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3814e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3668e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3522e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3376e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3230e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3085e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2940e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2795e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2650e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2506e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2362e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2218e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2074e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1930e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1787e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1644e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1501e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1358e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1216e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1074e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0932e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0790e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0648e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0507e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0366e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0225e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0084e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9944e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9803e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9663e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9524e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9384e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9245e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9106e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8967e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8828e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8689e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8551e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8413e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8275e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8138e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8000e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7863e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7726e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7589e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7453e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7316e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7180e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7044e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6908e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6773e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6638e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6502e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6368e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6233e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6098e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5964e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5830e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5696e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5563e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5429e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5296e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5163e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5030e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4898e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4765e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4633e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4501e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4370e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4238e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4107e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3975e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3845e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3714e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3583e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3453e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3323e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3193e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3063e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2934e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2804e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2675e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2546e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2418e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2289e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2161e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2033e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1905e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1777e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1650e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1522e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1395e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1268e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1142e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1015e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0889e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0763e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0637e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0511e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0385e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0260e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0135e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0010e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9885e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9761e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9636e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9512e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9388e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9264e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9141e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9017e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8894e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8771e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8648e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8526e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8403e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8281e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8159e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8037e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7915e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7794e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7673e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7551e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7431e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7310e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7189e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7069e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6949e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6829e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6709e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6589e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6470e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6351e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6232e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6113e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5994e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5876e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5757e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5639e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5521e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5404e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5286e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5169e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5051e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4934e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4818e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4701e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4584e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4468e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4352e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4236e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4120e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4005e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3889e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3774e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3659e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3544e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3430e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3315e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3201e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3087e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2973e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2859e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2745e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2632e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2519e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2406e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2293e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2180e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2067e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1955e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1843e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1731e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1619e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1507e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1396e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1284e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1173e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1062e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0952e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0841e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0730e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0620e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0510e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0400e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0290e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0181e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0071e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9962e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9853e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9744e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9635e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9527e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9418e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9310e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9202e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9094e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8986e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8879e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8771e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8664e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8557e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8450e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8343e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8237e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8131e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8024e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7918e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7812e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7707e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7601e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7496e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7390e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7285e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7180e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7076e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6971e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6867e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6762e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6658e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6554e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6451e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6347e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6243e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6140e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6037e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5934e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5831e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5729e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5626e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5524e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5422e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5320e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5218e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5116e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5015e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4913e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4812e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4711e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4610e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4509e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4409e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4308e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4208e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4108e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4008e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3908e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3808e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3709e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3610e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3510e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3411e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3313e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3214e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3115e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3017e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2919e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2821e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2723e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2625e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2527e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2430e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2332e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2235e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2138e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2041e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1944e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1848e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1751e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1655e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1559e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1463e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1367e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1271e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1176e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1081e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0985e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0890e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0795e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0701e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0606e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0511e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0417e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0323e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0229e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0135e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0041e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9947e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9854e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9761e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9667e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9574e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9482e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9389e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9296e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9204e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9111e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9019e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8927e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8835e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8744e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8652e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8561e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8469e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8378e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8287e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8196e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8105e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8015e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7924e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7834e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7744e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7654e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7564e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7474e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7385e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7295e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7206e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7117e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7028e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6939e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6850e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6761e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6673e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6584e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6496e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6408e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6320e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6232e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6145e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6057e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5970e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5882e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5795e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5708e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5621e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5535e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5448e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5362e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5275e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5189e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5103e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5017e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4931e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4846e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4760e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4675e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4589e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4504e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4419e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4335e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4250e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4165e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4081e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3996e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3912e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3828e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3744e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3660e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3577e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3493e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3410e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3327e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3243e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3160e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3078e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2995e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2912e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2830e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2747e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2665e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2583e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2501e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2419e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2337e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2256e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2174e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2093e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2012e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1931e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1850e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1769e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1688e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1607e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1527e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1447e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1366e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1286e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1206e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1126e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1047e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0967e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0888e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0808e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0729e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0650e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0571e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0492e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0413e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0335e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0256e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0178e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0100e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0022e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9944e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9866e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9788e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9710e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9633e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9556e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9478e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9401e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9324e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9247e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9170e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9094e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9017e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8941e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8864e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8788e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8712e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8636e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8560e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8485e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8409e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8334e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8258e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8183e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8108e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8033e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7958e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7883e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7808e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7734e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7660e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7585e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7511e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7437e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7363e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7289e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7215e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7142e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7068e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6995e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6922e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6848e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6775e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6702e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6630e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6557e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6484e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6412e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6339e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6267e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6195e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6123e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6051e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5979e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5908e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5836e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5765e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5693e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5622e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5551e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5480e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5409e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5338e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5267e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5197e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5126e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5056e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4986e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4916e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4846e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4776e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4706e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4636e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4567e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4497e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4428e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4358e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4289e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4220e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4151e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4082e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4014e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3945e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3876e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3808e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3740e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3672e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3603e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3535e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3468e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3400e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3332e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3265e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3197e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3130e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3063e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2995e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2928e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2861e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2795e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2728e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2661e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2595e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2528e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2462e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2396e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2330e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2264e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2198e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2132e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2066e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2001e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1935e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1870e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1804e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1739e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1674e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1609e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1544e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1480e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1415e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1350e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1286e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1221e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1157e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1093e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1029e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0965e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0901e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0837e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0774e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0710e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0647e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0583e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0520e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0457e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0394e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0331e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0268e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0205e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0142e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0080e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0017e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9955e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9893e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9830e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9768e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9706e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9644e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9583e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9521e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9459e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9398e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9336e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9275e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9214e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9153e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9091e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9031e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8970e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8909e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8848e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8788e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8727e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8667e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8606e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8546e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8486e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8426e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8366e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8306e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8247e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8187e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8128e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8068e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8009e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7949e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7890e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7831e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7772e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7713e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7655e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7596e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7537e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7479e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7420e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7362e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7304e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7245e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7187e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7129e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7072e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7014e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6956e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6898e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6841e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6783e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6726e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6669e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6612e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6555e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6498e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6441e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6384e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6327e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6270e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6214e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6157e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6101e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.6045e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5989e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5932e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5876e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5820e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5765e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5709e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5653e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5598e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5542e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5487e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5431e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5376e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5321e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5266e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5211e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5156e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5101e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.5046e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4992e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4937e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4883e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4828e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4774e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4720e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4666e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4612e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4558e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4504e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4450e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4396e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4343e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4289e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4236e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4182e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4129e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4076e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.4023e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3970e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3917e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3864e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3811e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3758e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3705e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3653e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3600e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3548e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3496e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3444e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3391e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3339e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3287e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3235e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3184e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3132e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3080e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.3029e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2977e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2926e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2874e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2823e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2772e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2721e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2670e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2619e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2568e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2517e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2467e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2416e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2365e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2315e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2265e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2214e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2164e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2114e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2064e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.2014e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1964e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1914e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1864e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1815e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1765e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1715e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1666e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1617e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1567e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1518e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1469e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1420e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1371e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1322e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1273e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1224e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1176e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1127e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1079e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.1030e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0982e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0933e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0885e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0837e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0789e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0741e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0693e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0645e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0597e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0550e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0502e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0454e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0407e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0360e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0312e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0265e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0218e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0171e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0124e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0077e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.0030e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9983e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9936e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9889e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9843e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9796e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9750e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9703e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9657e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9611e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9565e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9519e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9473e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9427e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9381e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9335e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9289e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9244e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9198e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9152e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9107e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9062e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.9016e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8971e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8926e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8881e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8836e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8791e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8746e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8701e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8656e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8612e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8567e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8522e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8478e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8434e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8389e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8345e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8301e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8257e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8213e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8169e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8125e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8081e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.8037e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7993e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7950e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7906e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7863e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7819e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7776e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7732e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7689e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7646e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7603e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7560e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7517e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7474e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7431e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7388e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7346e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7303e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7260e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7218e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7176e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7133e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7091e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7049e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.7006e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6964e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6922e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6880e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6838e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6797e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6755e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6713e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6671e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6630e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6588e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6547e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6505e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6464e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6423e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6382e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6341e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6299e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6258e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6217e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6177e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6136e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6095e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6054e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.6014e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5973e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5933e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5892e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5852e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5812e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5771e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5731e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5691e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5651e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5611e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5571e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5531e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5491e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5452e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5412e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5372e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5333e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5293e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5254e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5214e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5175e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5136e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5097e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5058e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.5018e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4979e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4940e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4902e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4863e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4824e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4785e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4747e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4708e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4670e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4631e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4593e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4554e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4516e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4478e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4440e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4402e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4363e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4325e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4288e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4250e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4212e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4174e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4136e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4099e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4061e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.4024e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3986e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3949e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3911e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3874e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3837e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3800e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3763e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3726e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3689e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3652e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3615e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3578e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3541e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3505e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3468e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3431e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3395e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3358e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3322e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3286e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3249e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3213e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3177e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3141e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3105e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3069e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.3033e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2997e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2961e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2925e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2889e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2854e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2818e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2782e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2747e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2711e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2676e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2641e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2605e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2570e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2535e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2500e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2465e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2430e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2395e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2360e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2325e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2290e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2255e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2221e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2186e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2151e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2117e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2082e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2048e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.2013e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1979e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1945e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1911e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1876e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1842e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1808e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1774e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1740e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1706e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1673e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1639e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1605e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1571e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1538e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1504e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1471e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1437e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1404e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1370e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1337e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1304e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1271e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1237e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1204e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1171e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1138e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1105e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1072e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1039e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.1007e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0974e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0941e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0909e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0876e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0843e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0811e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0778e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0746e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0714e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0681e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0649e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0617e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0585e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0553e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0521e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0489e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0457e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0425e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0393e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0361e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0329e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0298e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0266e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0235e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0203e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0171e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0140e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0109e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0077e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0046e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(2.0015e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9983e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9952e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9921e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9890e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9859e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9828e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9797e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9766e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9736e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9705e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9674e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9643e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9613e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9582e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9552e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9521e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9491e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9460e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9430e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9400e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9369e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9339e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9309e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9279e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9249e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9219e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9189e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9159e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9129e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9099e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9070e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9040e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.9010e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8980e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8951e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8921e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8892e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8862e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8833e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8804e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8774e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8745e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8716e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8687e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8657e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8628e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8599e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8570e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8541e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8512e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8484e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8455e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8426e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8397e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8369e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8340e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8311e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8283e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8254e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8226e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8197e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8169e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8141e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8112e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8084e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8056e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8028e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.8000e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7972e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7944e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7916e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7888e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7860e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7832e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7804e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7776e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7749e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7721e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7693e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7666e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7638e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7611e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7583e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7556e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7528e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7501e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7474e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7447e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7419e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7392e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7365e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7338e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7311e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7284e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7257e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7230e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7203e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7176e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7150e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7123e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7096e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7070e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7043e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.7016e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6990e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6963e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6937e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6911e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6884e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6858e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6832e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6805e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6779e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6753e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6727e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6701e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6675e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6649e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6623e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6597e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6571e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6545e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6519e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6494e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6468e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6442e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6417e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6391e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6365e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6340e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6314e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6289e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6264e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6238e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6213e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6188e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6162e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6137e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6112e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6087e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6062e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6037e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.6012e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5987e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5962e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5937e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5912e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5887e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5862e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5838e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5813e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5788e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5764e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5739e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5715e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5690e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5666e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5641e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5617e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5593e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5568e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5544e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5520e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5496e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5471e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5447e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5423e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5399e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5375e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5351e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5327e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5303e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5279e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5256e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5232e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5208e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5184e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5161e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5137e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5113e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5090e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5066e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5043e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.5019e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4996e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4973e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4949e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4926e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4903e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4879e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4856e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4833e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4810e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4787e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4764e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4741e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4718e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4695e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4672e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4649e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4626e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4603e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4581e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4558e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4535e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4512e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4490e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4467e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4445e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4422e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4400e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4377e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4355e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4332e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4310e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4288e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4266e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4243e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4221e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4199e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4177e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4155e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4133e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4111e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4089e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4067e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4045e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4023e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.4001e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3979e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3957e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3935e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3914e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3892e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3870e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3849e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3827e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3806e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3784e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3763e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3741e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3720e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3698e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3677e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3656e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3634e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3613e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3592e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3571e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3550e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3528e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3507e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3486e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3465e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3444e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3423e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3402e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3381e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3361e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3340e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3319e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3298e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3277e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3257e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3236e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3215e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3195e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3174e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3154e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3133e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3113e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3092e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3072e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3051e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3031e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.3011e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2990e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2970e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2950e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2930e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2910e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2890e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2869e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2849e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2829e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2809e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2789e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2769e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2749e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2730e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2710e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2690e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2670e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2650e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2631e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2611e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2591e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2572e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2552e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2533e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2513e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2493e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2474e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2455e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2435e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2416e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2396e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2377e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2358e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2338e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2319e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2300e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2281e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2262e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2243e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2223e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2204e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2185e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2166e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2147e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2128e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2110e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2091e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2072e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2053e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2034e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.2015e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1997e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1978e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1959e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1941e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1922e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1903e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1885e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1866e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1848e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1829e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1811e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1793e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1774e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1756e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1737e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1719e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1701e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1683e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1664e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1646e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1628e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1610e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1592e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1574e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1556e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1538e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1520e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1502e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1484e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1466e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1448e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1430e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1412e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1395e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1377e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1359e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1341e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1324e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1306e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1288e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1271e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1253e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1236e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1218e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1201e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1183e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1166e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1148e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1131e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1114e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1096e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1079e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1062e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1044e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1027e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.1010e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0993e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0976e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0959e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0942e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0924e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0907e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0890e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0873e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0856e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0840e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0823e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0806e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0789e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0772e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0755e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0739e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0722e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0705e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0688e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0672e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0655e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0638e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0622e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0605e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0589e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0572e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0556e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0539e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0523e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0506e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0490e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0474e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0457e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0441e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0425e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0409e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0392e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0376e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0360e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0344e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0328e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0312e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0296e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0279e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0263e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0247e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0231e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0215e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0200e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0184e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0168e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0152e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0136e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0120e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0105e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0089e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0073e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0057e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0042e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0026e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1.0010e-06, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9947e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9791e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9636e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9480e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9325e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9171e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9016e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8861e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8707e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8553e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8400e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8246e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.8093e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7940e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7787e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7635e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7483e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7331e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7179e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.7027e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6876e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6725e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6574e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6424e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6273e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.6123e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5973e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5824e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5674e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5525e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5376e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5227e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.5079e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4931e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4783e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4635e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4487e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4340e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4193e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4046e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3899e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3753e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3607e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3461e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3315e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3170e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.3024e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2879e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2734e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2590e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2446e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2301e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2157e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.2014e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1870e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1727e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1584e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1441e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1299e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1156e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.1014e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0872e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0731e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0589e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0448e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0307e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0166e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.0025e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9885e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9745e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9605e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9465e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9326e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9186e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9047e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8908e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8770e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8631e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8493e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8355e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8217e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.8080e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7943e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7805e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7669e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7532e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7395e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7259e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.7123e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6987e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6852e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6716e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6581e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6446e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6311e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6177e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.6042e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5908e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5774e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5640e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5507e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5373e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5240e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5107e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4975e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4842e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4710e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4578e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4446e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4314e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4183e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.4052e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3921e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3790e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3659e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3529e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3398e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3268e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3138e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.3009e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2879e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2750e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2621e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2492e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2364e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2235e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.2107e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1979e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1851e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1724e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1596e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1469e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1342e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1215e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.1088e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0962e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0836e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0710e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0584e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0458e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0333e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0207e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0082e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9958e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9833e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9708e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9584e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9460e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9336e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9212e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.9089e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8966e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8842e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8719e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8597e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8474e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8352e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8230e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.8108e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7986e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7864e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7743e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7622e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7501e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7380e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7259e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7139e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.7018e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6898e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6778e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6659e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6539e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6420e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6301e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6182e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6063e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5944e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5826e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5708e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5590e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5472e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5354e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5237e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5119e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.5002e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4885e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4768e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4652e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4535e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4419e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4303e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4187e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.4072e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3956e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3841e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3726e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3611e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3496e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3381e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3267e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3153e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3039e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2925e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2811e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2697e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2584e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2471e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2358e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2245e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2132e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.2020e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1908e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1796e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1684e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1572e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1460e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1349e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1238e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1126e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.1016e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0905e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0794e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0684e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0574e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0464e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0354e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0244e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0135e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.0025e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9916e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9807e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9698e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9589e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9481e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9373e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9264e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9156e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9049e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8941e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8833e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8726e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8619e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8512e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8405e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8298e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8192e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.8086e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7979e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7874e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7768e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7662e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7557e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7451e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7346e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7241e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7136e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.7031e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6927e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6823e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6718e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6614e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6510e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6407e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6303e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6200e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6097e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5994e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5891e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5788e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5685e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5583e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5481e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5379e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5277e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5175e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.5073e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4972e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4870e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4769e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4668e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4567e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4467e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4366e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4266e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4166e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.4066e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3966e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3866e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3766e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3667e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3568e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3469e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3370e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3271e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3172e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.3074e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2975e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2877e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2779e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2681e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2583e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2486e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2388e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2291e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2194e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2097e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2000e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1904e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1807e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1711e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1614e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1518e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1422e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1327e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1231e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1136e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.1040e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0945e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0850e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0755e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0660e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0566e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0471e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0377e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0283e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0189e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0095e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.0001e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9908e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9814e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9721e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9628e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9535e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9442e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9350e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9257e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9165e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9072e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8980e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8888e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8796e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8705e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8613e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8522e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8431e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8340e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8249e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8158e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.8067e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7976e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7886e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7796e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7706e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7616e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7526e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7436e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7347e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7257e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7168e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.7079e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6990e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6901e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6812e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6724e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6635e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6547e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6459e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6371e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6283e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6195e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6107e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.6020e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5933e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5845e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5758e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5671e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5585e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5498e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5411e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5325e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5239e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5153e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.5067e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4981e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4895e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4809e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4724e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4639e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4553e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4468e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4383e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4299e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4214e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4129e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.4045e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3961e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3877e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3793e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3709e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3625e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3541e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3458e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3374e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3291e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3208e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3125e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.3042e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2960e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2877e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2795e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2712e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2630e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2548e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2466e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2384e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2303e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2221e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2140e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.2058e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1977e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1896e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1815e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1734e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1654e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1573e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1493e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1412e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1332e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1252e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1172e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1093e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.1013e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0933e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0854e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0775e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0695e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0616e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0538e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0459e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0380e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0301e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0223e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0145e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.0067e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9988e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9911e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9833e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9755e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9677e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9600e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9523e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9445e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9368e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9291e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9214e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9138e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.9061e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8985e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8908e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8832e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8756e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8680e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8604e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8528e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8452e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8377e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8301e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8226e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8151e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8076e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.8001e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7926e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7851e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7777e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7702e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7628e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7554e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7479e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7405e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7331e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7258e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7184e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7110e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.7037e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6964e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6890e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6817e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6744e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6671e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6599e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6526e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6453e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6381e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6309e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6236e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6164e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6092e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.6021e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5949e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5877e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5806e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5734e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5663e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5592e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5521e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5450e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5379e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5308e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5237e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5167e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5096e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.5026e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4956e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4886e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4816e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4746e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4676e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4606e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4537e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4467e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4398e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4329e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4260e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4191e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4122e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.4053e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3984e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3916e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3847e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3779e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3711e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3642e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3574e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3506e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3439e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3371e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3303e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3236e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3168e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3101e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.3034e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2967e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2900e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2833e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2766e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2699e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2633e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2566e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2500e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2434e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2368e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2301e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2235e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2170e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2104e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.2038e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1973e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1907e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1842e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1777e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1712e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1646e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1582e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1517e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1452e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1387e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1323e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1258e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1194e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1130e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1066e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.1002e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0938e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0874e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0810e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0747e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0683e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0620e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0556e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0493e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0430e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0367e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0304e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0241e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0178e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0116e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(4.0053e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9991e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9928e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9866e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9804e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9742e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9680e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9618e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9556e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9494e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9433e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9371e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9310e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9249e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9188e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9126e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9065e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.9004e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8944e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8883e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8822e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8762e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8701e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8641e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8581e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8521e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8461e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8401e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8341e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8281e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8221e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8162e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8102e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.8043e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7983e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7924e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7865e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7806e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7747e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7688e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7629e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7571e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7512e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7454e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7395e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7337e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7279e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7221e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7163e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7105e-07, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(3.7047e-07, grad_fn=<MeanBackward0>)\n",
      "Final training parameters: Z_eff: Parameter containing:\n",
      "tensor(1.1546, requires_grad=True) alpha: tensor(2.2097)\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "rep_feed = RepulsiveSplineFeed(Z_eff_map=z_effs, alpha_map=alphas, device=device, dtype=torch.float64)\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    rep_energy = 2 * rep_feed(geometry)\n",
    "   \n",
    "    loss = mse_loss(rep_energy, targets['repulsive_energy'])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\"loss:\",loss)\n",
    "    # Record loss\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "print(\"Final training parameters: Z_eff:\", z_effs[1], \"alpha:\", alphas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0b094e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.5\n",
    "plt.tick_params(direction='in', labelsize='26', width=1.5, length=5, top='on',\n",
    "                right='on', zorder=10)\n",
    "plt.plot(range(number_of_epochs), loss_list)\n",
    "plt.xlabel(\"Iteration\", fontsize=28)\n",
    "plt.ylabel(\"Loss\", fontsize=28)\n",
    "plt.title(\"Training Loss Over Time\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
